{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2170465,"sourceType":"datasetVersion","datasetId":1165452}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/muhammedkoca/akbank-derin-renme-bal-k-ay-rt-etme?scriptVersionId=202881129\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<h1 style=\" text-align:center; color:Blue; font-size:40px; display: block;\"> <u><b><i>Fish Classification üêüüêüüêü</i></b></u> </h1>\n<p style=\"text-align:center; \">\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/23/Georgia_Aquarium_-_Giant_Grouper_edit.jpg\" style='width: 400px;'>\n</p>\n","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\" text-align:center; color:Blue; font-size:40px; display: block;\"> <u><b><i>Dataset Hakkƒ±nda Bilgi</i></b></u> </h2>","metadata":{}},{"cell_type":"markdown","source":"**Segmentasyon ve Sƒ±nƒ±flandƒ±rma i√ßin Geni≈ü √ñl√ßekli Bir Veri Seti**\n\nYazarlar: O. Ulucan, D. Karakaya, M. Turkan\n\nƒ∞zmir Ekonomi √úniversitesi, Elektrik-Elektronik\n\nM√ºhendisliƒüi B√∂l√ºm√º, ƒ∞zmir, T√ºrkiye\n\nƒ∞leti≈üim: M. Turkan - mehmet.turkan@ieu.edu.tr\n\nMakale: Balƒ±k Segmentasyonu ve Sƒ±nƒ±flandƒ±rmasƒ± i√ßin Geni≈ü √ñl√ßekli Bir Veri Seti\n\n**Genel Giri≈ü**\n\nBu veri seti, ƒ∞zmir Ekonomi √úniversitesi'nde bir √ºniversite-sanayi i≈übirliƒüi projesi kapsamƒ±nda ƒ∞zmir'deki bir s√ºpermarketten toplanan 9 farklƒ± deniz √ºr√ºn√º t√ºr√ºn√º i√ßermektedir ve bu √ßalƒ±≈üma ASYU 2020'de yayƒ±nlanmƒ±≈ütƒ±r. Veri seti √ßipura, kƒ±rmƒ±zƒ± mercan, levrek, kƒ±rmƒ±zƒ± barbun, istavrit, hamsi, tekir, alabalƒ±k ve karides g√∂r√ºnt√º √∂rneklerini i√ßermektedir.\n\n**Veri Setinin A√ßƒ±klamasƒ±**\n\nVeri seti 9 farklƒ± deniz √ºr√ºn√º t√ºr√º i√ßermektedir. Her sƒ±nƒ±f i√ßin 1000 artƒ±rƒ±lmƒ±≈ü g√∂r√ºnt√º ve bunlarƒ±n e≈üle≈ütirilmi≈ü artƒ±rƒ±lmƒ±≈ü ground truth'larƒ± bulunmaktadƒ±r. Her sƒ±nƒ±f, ground truth etiketleriyle birlikte \"Fish_Dataset\" dosyasƒ±nda bulunabilir. Her sƒ±nƒ±ftaki t√ºm g√∂r√ºnt√ºler \"00000.png\"den \"01000.png\"ye kadar sƒ±ralanmƒ±≈ütƒ±r.\n   ","metadata":{}},{"cell_type":"markdown","source":"# 1 - K√ºt√ºphaneler","metadata":{}},{"cell_type":"markdown","source":"### 1-Veri Manip√ºlasyonu ve Analizi:\n\n**import numpy as np** Sayƒ±sal i≈ülemler ve √ßok boyutlu diziler i√ßin\n\n**import pandas as pd**Veri analizi ve manip√ºlasyonu i√ßin DataFrame yapƒ±sƒ± sunar\n\n\n### 2-G√∂rselle≈ütirme K√ºt√ºphaneleri:\n\n**import matplotlib.pyplot as plt** Temel g√∂rselle≈ütirme k√ºt√ºphanesi\n\n**%matplotlib inline** Jupyter notebook'ta grafikleri direkt g√∂sterir\n\n**import seaborn as sns** ƒ∞statistiksel veri g√∂rselle≈ütirme k√ºt√ºphanesi\n\n### 3-Sistem ve Dosya ƒ∞≈ülemleri:\n\n**import os** Dosya ve dizin i≈ülemleri i√ßin\n\n### 4-Makine √ñƒürenmesi Metrikleri:\n\n**from sklearn.metrics import classification_report, confusion_matrix, accuracy_score**\nclassification_report: Sƒ±nƒ±flandƒ±rma modelinin detaylƒ± performans raporu\nconfusion_matrix: Hata matrisi olu≈üturur\n accuracy_score: Doƒüruluk oranƒ±nƒ± hesaplar\n\n**from sklearn.model_selection import train_test_split**\nVeriyi eƒüitim ve test setlerine b√∂lmek i√ßin\n\n### 5-TensorFlow ve Keras (Derin √ñƒürenme):\n\n**import tensorflow as tf** Derin √∂ƒürenme k√ºt√ºphanesi\n\n**from tensorflow import keras** Y√ºksek seviyeli sinir aƒüƒ± API'si\n\n**from tensorflow.keras import layers**  Sinir aƒüƒ± katmanlarƒ±\n\n**from tensorflow.keras.preprocessing.image import ImageDataGenerator** G√∂r√ºnt√º i≈üleme i√ßin veri artƒ±rma/√∂n i≈üleme\n\n**from tensorflow.keras.applications.mobilenet_v2 import preprocess_input** G√∂r√ºnt√º verileri √∂n i≈ülenerek modelin daha iyi performans g√∂stermesine yardƒ±mcƒ± olur.\n\n**from tensorflow.python.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential**  Sinir aƒüƒ± katmanlarƒ± ve model yapƒ±sƒ±\n\n**from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy** Model optimizasyonu ve kayƒ±p fonksiyonu\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2 - Veri Setinin Y√ºklenmesi","metadata":{}},{"cell_type":"markdown","source":"**NOT:**  Bu kod genellikle makine √∂ƒürenmesi projelerinde sƒ±nƒ±f isimlerini otomatik olarak almak i√ßin kullanƒ±lƒ±r. Her bir klas√∂r bir balƒ±k t√ºr√ºn√º (sƒ±nƒ±fƒ±nƒ±) temsil ediyor olacaktƒ±r.Classes ile veri setimizde ka√ß √ße≈üit balƒ±k olduƒüunu burdan g√∂rebiliriz.","metadata":{}},{"cell_type":"code","source":"fish_dir = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset' \nclasses = [i for i in os.listdir(fish_dir) if '.' not in i]                    \nclasses","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**label = []** Balƒ±k t√ºrlerinin etiketlerini tutacak liste\n\n**path = []** G√∂r√ºnt√º dosyalarƒ±nƒ±n yollarƒ±nƒ± tutacak liste\n\n**if os.path.splitext(filename)[-1]=='.png':** Bu satƒ±r sadece PNG formatƒ±ndaki g√∂r√ºnt√º dosyalarƒ±nƒ± se√ßiyor ve Belirtilen dizinde ve alt dizinlerde t√ºm PNG dosyalarƒ±nƒ± buluyor.Her PNG dosyasƒ±nƒ±n tam yolunu path listesine ekliyor\nDosyanƒ±n bulunduƒüu klas√∂r adƒ±nƒ± (balƒ±k t√ºr√ºn√º) label listesine ekliyor\n\n**NOT:** Bu kod genellikle g√∂r√ºnt√º sƒ±nƒ±flandƒ±rma projeleri i√ßin veri setini organize etmek amacƒ±yla kullanƒ±lƒ±r. Her bir g√∂r√ºnt√ºn√ºn yolunu ve hangi balƒ±k t√ºr√ºne ait olduƒüunu d√ºzenli bir ≈üekilde tutar.\n\nBu kodun amacƒ± ve yaptƒ±klarƒ±,DataFrame Olu≈üturma:ƒ∞ki s√ºtunlu bo≈ü bir tablo yapƒ±sƒ± olu≈üturur:\n\n**'path'** s√ºtunu: G√∂r√ºnt√º dosyalarƒ±nƒ±n yollarƒ±nƒ± tutar.\n**'label'** s√ºtunu: Balƒ±k t√ºrlerinin isimlerini tutar.\n\n**Bu Yapƒ±nƒ±n Avantajlarƒ±:**\n\nD√ºzenli veri organizasyonu saƒülar.\n\nHer g√∂r√ºnt√ºn√ºn hangi sƒ±nƒ±fa ait olduƒüunu kolayca g√∂sterir.\n\nVeriyle √ßalƒ±≈ümayƒ± kolayla≈ütƒ±rƒ±r.\n\nMakine √∂ƒürenmesi modeli i√ßin veriyi hazƒ±r hale getirir.\n\n\n**Kullanƒ±m Ama√ßlarƒ±:**\n\nVeri setini organize etmek.\n\nModel eƒüitimi i√ßin veriyi hazƒ±rlamak.\n\nƒ∞statistiksel analizler yapmak.\n\nVeri setini incelemek ve kontrol etmek.\n","metadata":{}},{"cell_type":"code","source":"label = []\npath = []\n\nfor dir_name, _,filenames in os.walk(fish_dir):                    \n    for filename in filenames:                                 \n        if os.path.splitext(filename)[-1]=='.png':               # If filename contains .png\n            if dir_name.split()[-1]!='GT':                       # If directory doesn't contain GT\n                label.append(os.path.split(dir_name)[-1])         # Append the directory name to label \n                path.append(os.path.join(dir_name,filename))     # Append all the png files to path of that directory\n\ndata = pd.DataFrame(columns=['path','label'])\ndata['path']=path\ndata['label']=label","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3 - Veri Setinin ƒ∞ncelenmesi ( EDA )","metadata":{}},{"cell_type":"code","source":"# ƒ∞lk 5 data hakkƒ±nda bilgi verir.\ndata.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Son 5 data hakkƒ±nda bilgi verir.\ndata.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()\n# Bu kod sayesinde 9000 tane fotograf ve path olduƒüunu g√∂rebiliriz.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ƒ∞lk resmin path yolunu okumamƒ±zƒ± saƒülar\ndata.path[0]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Her balƒ±k √ße≈üidi ka√ß tane fotograf var olduƒüunu g√∂sterir..\ndata.label.value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Her balƒ±k √ße≈üidi pasta ve √ßubuk grafik ile de g√∂relim.\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.countplot(data=data, x='label')\nplt.xticks(rotation=60)\n\n# Sƒ±nƒ±flarƒ±n pasta grafiƒüi\nplt.subplot(1,2,2)\nplt.pie(x=data['label'].value_counts().values,\n        labels=data['label'].value_counts().index,\n        autopct='%1.1f%%')\n\n# Genel ba≈ülƒ±k ve g√∂sterim\nplt.suptitle('Veride Bulunan Balƒ±k Sƒ±nƒ±flarƒ±nƒ±n Daƒüƒ±lƒ±mƒ±', size=20)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cn = 0\n# Fig√ºr boyutunu ayarla (20x20 in√ß)\nplt.figure(figsize=(20,20))\n\n# Her bir benzersiz balƒ±k t√ºr√º i√ßin d√∂ng√º\nfor unique_label in data[\"label\"].unique():\n    # 3x3'l√ºk bir grid olu≈ütur ve sƒ±rayla her bir h√ºcreye bir g√∂r√ºnt√º yerle≈ütir\n    plt.subplot(3,3,cn+1)\n    \n    # O balƒ±k t√ºr√ºne ait ilk g√∂r√ºnt√ºy√º se√ß ve g√∂ster\n    plt.imshow(plt.imread(data[data[\"label\"]==unique_label].iloc[0,0]))\n    \n    # G√∂r√ºnt√ºn√ºn √ºzerine balƒ±k t√ºr√ºn√ºn ismini yaz\n    plt.title(unique_label)\n    \n    # Eksenleri gizle\n    plt.axis(\"off\")\n    \n    # Sayacƒ± bir artƒ±r\n    cn+=1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**NOT:** Bu kod balƒ±k veri setindeki her bir t√ºrden bir √∂rnek g√∂r√ºnt√ºy√º yan yana g√∂stermek i√ßin kullanƒ±lƒ±yor.\n\n**Bu kod √∂zellikle:**\n\nVeri setini g√∂rsel olarak incelemek\n\nHer balƒ±k t√ºr√ºnden bir √∂rnek g√∂rmek\n\nVeri setinin √ße≈üitliliƒüini anlamak\n\nG√∂r√ºnt√º kalitesini kontrol etmek i√ßin kullanƒ±≈ülƒ±dƒ±r.\n\n\nHer bir g√∂r√ºnt√ºn√ºn √ºzerinde o balƒ±k t√ºr√ºn√ºn ismi yazƒ±lƒ± olacak ve 3x3'l√ºk bir d√ºzende toplam 9 farklƒ± balƒ±k t√ºr√º g√∂sterilecektir.","metadata":{}},{"cell_type":"markdown","source":"## 3.1 - Shrimp -> Karides ƒ∞lk 4 G√∂r√ºnt√ºs√º","metadata":{}},{"cell_type":"code","source":"shrimps=data[data[\"label\"]==\"Shrimp\"].path.iloc[0:4]\ncn = 0\nplt.figure(figsize=(20,20))\nfor shrimp in shrimps:\n    plt.subplot(int(np.sqrt(len(shrimps))), int(np.sqrt(len(shrimps))),cn+1)\n    plt.imshow(plt.imread(shrimp))\n    plt.title(shrimp[-9:-4])\n    plt.axis(\"off\")\n    cn+=1\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**NOT:** Bu kod balƒ±k veri setindeki her bir t√ºrden bir √∂rnek g√∂r√ºnt√ºy√º yan yana g√∂stermek i√ßin kullanƒ±lƒ±yor.","metadata":{}},{"cell_type":"markdown","source":"## 3.2 - Hourse Mackerel -> ƒ∞stavrit ƒ∞lk 4 G√∂r√ºnt√ºs√º","metadata":{}},{"cell_type":"code","source":"istavritler = data[data[\"label\"]==\"Hourse Mackerel\"].path.iloc[0:4]\ncn = 0\nplt.figure(figsize=(20,20))\nfor istavrit in istavritler:\n    plt.subplot(int(np.sqrt(len(istavritler))), int(np.sqrt(len(istavritler))), cn+1)\n    plt.imshow(plt.imread(istavrit))\n    plt.title(istavrit[-9:-4])\n    plt.axis(\"off\")\n    cn += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.3 - Black Sea Sprat -> Hamsi ƒ∞lk 4 G√∂r√ºnt√ºs√º","metadata":{}},{"cell_type":"code","source":"hamsiler = data[data[\"label\"]==\"Black Sea Sprat\"].path.iloc[0:4]\ncn = 0\nplt.figure(figsize=(20,20))\nfor hamsi in hamsiler:\n    plt.subplot(int(np.sqrt(len(hamsiler))), int(np.sqrt(len(hamsiler))), cn+1)\n    plt.imshow(plt.imread(hamsi))\n    plt.title(hamsi[-9:-4])\n    plt.axis(\"off\")\n    cn += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ### 3.4 -Sea Bass -> Levrek ƒ∞lk 4 G√∂r√ºnt√ºs√º","metadata":{}},{"cell_type":"code","source":"levrekler = data[data[\"label\"]==\"Sea Bass\"].path.iloc[0:4]\ncn = 0\nplt.figure(figsize=(20,20))\nfor levrek in levrekler:\n    plt.subplot(int(np.sqrt(len(levrekler))), int(np.sqrt(len(levrekler))), cn+1)\n    plt.imshow(plt.imread(levrek))\n    plt.title(levrek[-9:-4])\n    plt.axis(\"off\")\n    cn += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.5 - Red Mullet -> Barbun ƒ∞lk 4 G√∂r√ºnt√ºs√º","metadata":{}},{"cell_type":"code","source":"barbunlar = data[data[\"label\"]==\"Red Mullet\"].path.iloc[0:4]\ncn = 0\nplt.figure(figsize=(20,20))\nfor barbun in barbunlar:\n    plt.subplot(int(np.sqrt(len(barbunlar))), int(np.sqrt(len(barbunlar))), cn+1)\n    plt.imshow(plt.imread(barbun))\n    plt.title(barbun[-9:-4])\n    plt.axis(\"off\")\n    cn += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.6 - Trout -> Alabalƒ±k ƒ∞lk 4 G√∂r√ºnt√ºs√º","metadata":{}},{"cell_type":"code","source":"alabalƒ±klar = data[data[\"label\"]==\"Trout\"].path.iloc[0:4]\ncn = 0\nplt.figure(figsize=(20,20))\nfor alabalƒ±k in alabalƒ±klar:\n    plt.subplot(int(np.sqrt(len(alabalƒ±klar))), int(np.sqrt(len(alabalƒ±klar))), cn+1)\n    plt.imshow(plt.imread(alabalƒ±k))\n    plt.title(alabalƒ±k[-9:-4])\n    plt.axis(\"off\")\n    cn += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.7 - Striped Red Mullet -> Tekir ƒ∞lk 4 G√∂r√ºnt√ºs√º","metadata":{}},{"cell_type":"code","source":"tekirler = data[data[\"label\"]==\"Striped Red Mullet\"].path.iloc[0:4]\ncn = 0\nplt.figure(figsize=(20,20))\nfor tekir in tekirler:\n    plt.subplot(int(np.sqrt(len(tekirler))), int(np.sqrt(len(tekirler))), cn+1)\n    plt.imshow(plt.imread(tekir))\n    plt.title(tekir[-9:-4])\n    plt.axis(\"off\")\n    cn += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.8 - Gilt-Head Bream -> √áipura ƒ∞lk 4 G√∂r√ºnt√ºs√º","metadata":{}},{"cell_type":"code","source":"cipuralar = data[data[\"label\"]==\"Gilt-Head Bream\"].path.iloc[0:4]\ncn = 0\nplt.figure(figsize=(20,20))\nfor cipura in cipuralar:\n    plt.subplot(int(np.sqrt(len(cipuralar))), int(np.sqrt(len(cipuralar))), cn+1)\n    plt.imshow(plt.imread(cipura))\n    plt.title(cipura[-9:-4])\n    plt.axis(\"off\")\n    cn += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.9 - Red Sea Bream -> Kƒ±rmƒ±zƒ± Mercan ƒ∞lk 4 G√∂r√ºnt√ºs√º","metadata":{}},{"cell_type":"code","source":"mercanlar = data[data[\"label\"]==\"Red Sea Bream\"].path.iloc[0:4]\ncn = 0\nplt.figure(figsize=(20,20))\nfor mercan in mercanlar:\n    plt.subplot(int(np.sqrt(len(mercanlar))), int(np.sqrt(len(mercanlar))), cn+1)\n    plt.imshow(plt.imread(mercan))\n    plt.title(mercan[-9:-4])\n    plt.axis(\"off\")\n    cn += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4 - Veri ƒ∞≈üleme (Data Preprocessing)","metadata":{}},{"cell_type":"markdown","source":"Veri setinin d√ºzg√ºn bir ≈üekilde eƒüitilmesi i√ßin resimlerin i≈ülenmesi ve hazƒ±rlanmasƒ± gerekir.  ","metadata":{}},{"cell_type":"code","source":"train_data, test_data = train_test_split(data, test_size=0.2, shuffle=True, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Genel Ama√ß**\n\nEƒüitim i√ßin: **train_generator**, modelin eƒüitim verileri √ºzerinde veri artƒ±rma ve √∂n i≈üleme yaparak daha √ße≈üitli bir veri seti olu≈üturur. Ayrƒ±ca veriyi eƒüitim ve doƒürulama setlerine ayƒ±rƒ±r.\n\nTest i√ßin: **test_generator***, sadece test verilerini modelin ihtiya√ß duyduƒüu ≈üekilde √∂n i≈üler, ancak test verileri √ºzerinde herhangi bir veri artƒ±rma yapmaz.\n\nBu t√ºr jenerat√∂rler b√ºy√ºk veri setleri ile √ßalƒ±≈üƒ±rken olduk√ßa faydalƒ±dƒ±r, √ß√ºnk√º veriyi anƒ±nda y√ºkler ve d√∂n√º≈üt√ºr√ºr, bu sayede bellekte √ßok fazla yer kaplamadan b√ºy√ºk veri setleri ile i≈ülem yapabiliriz.","metadata":{}},{"cell_type":"code","source":"train_generator = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2,    \n)\n\nval_generator = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2    \n)\n\ntest_generator = ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Genel Ama√ß:**\n\r\nBu kod, modelin eƒüitilmei, doƒürulanmaƒ±  ve test  edilmesi i√ßin gerekli olan g√∂r√ºnt√º verilerini dinamik olarak y√ºklemeye ve i≈ülemeye olanak tanƒ±r. G√∂r√ºnt√º dosyalarƒ±nƒ±n yollarƒ± ve etiketleri DataFrame √ºzerinden alƒ±ndƒ±ƒüƒ± i√ßin, bu y√∂ntem b√ºy√ºk veri setleri ile √ßalƒ±≈üƒ±rken belleƒüi daha verimli kullanmanƒ±za yardƒ±mcƒ± olur. Ayrƒ±ca, veri artƒ±rma ve √∂n i≈üleme i≈ülemleri, modelin genel performansƒ±nƒ± artƒ±rmak i√ßin otomatik olarak uygulanƒ±r.","metadata":{}},{"cell_type":"code","source":"train_images = train_generator.flow_from_dataframe(dataframe=train_data, x_col='path', y_col='label', target_size=(224, 224), color_mode='rgb', class_mode='categorical', batch_size=32, shuffle=True, seed=42, subset='training')\nval_images = train_generator.flow_from_dataframe(dataframe=train_data, x_col='path', y_col='label', target_size=(224, 224), color_mode='rgb', class_mode='categorical', batch_size=32, shuffle=True, seed=42, subset='validation' )\ntest_images = test_generator.flow_from_dataframe(dataframe=test_data, x_col='path', y_col='label', target_size=(224, 224), color_mode='rgb', class_mode='categorical', batch_size=32, shuffle=False )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(train_images.class_indices)\ndisplay(val_images.class_indices)\ndisplay(test_images.class_indices)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.1 - Test Verilerin G√∂rselle≈ütirilmesi\n\nTest verisinden alƒ±ndan 6 g√∂r√ºnt√ºy√º ve etiketini yan yana g√∂rselle≈ütirir. G√∂r√ºnt√ºler, her biri i√ßin etiketleriyle birlikte alt grafiklerde g√∂sterilir. Bu t√ºr bir g√∂rselle≈ütirme, modelin tahminlerini ve g√∂r√ºnt√º verilerini deƒüerlendirmek i√ßin olduk√ßa faydalƒ±dƒ±r.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(20,20))\nax = ax.flatten()\n\nfor j in range(6):\n    img, label = next(test_images)  \n    \n    \n    if isinstance(label, (list, np.ndarray)):\n        label = label[0]\n    \n    if not isinstance(label, str):\n        label = str(label)\n    \n    ax[j].imshow(img[0])  \n    ax[j].set_title(label)  \n    ax[j].axis('off')\n\nplt.tight_layout()  \nplt.show()  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2 - Train Verilerin G√∂rselle≈ütirilmesi\n\nTrain verisinden alƒ±ndan 6 g√∂r√ºnt√ºy√º ve etiketini yan yana g√∂rselle≈ütirir. G√∂r√ºnt√ºler, her biri i√ßin etiketleriyle birlikte alt grafiklerde g√∂sterilir. Bu t√ºr bir g√∂rselle≈ütirme, modelin tahminlerini ve g√∂r√ºnt√º verilerini deƒüerlendirmek i√ßin olduk√ßa faydalƒ±dƒ±r.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(20, 20))\nax = ax.flatten()\n\nfor j in range(6):\n    img, label = next(train_images)  # Eƒüitim veri k√ºmesinden g√∂r√ºnt√º ve etiket al\n\n    if isinstance(label, (list, np.ndarray)):\n        label = label[0]\n    \n    if not isinstance(label, str):\n        label = str(label)\n    \n    ax[j].imshow(img[0])  \n    ax[j].set_title(label)  \n    ax[j].axis('off')\n\nplt.tight_layout()  \nplt.suptitle('Train Images', fontsize=24)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.3 - Validation Verilerin G√∂rselle≈ütirilmesi\n\rValidationn verisinden alƒ±ndan 6 g√∂r√ºnt√ºy√º ve etiketini yan yana g√∂rselle≈ütirir. G√∂r√ºnt√ºler, her biri i√ßin etiketleriyle birlikte alt grafiklerde g√∂sterilir. Bu t√ºr bir g√∂rselle≈ütirme, modelin tahminlerini ve g√∂r√ºnt√º verilerini deƒüerlendirmek i√ßin olduk√ßa faydalƒ±dƒ±r.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(20, 20))\nax = ax.flatten()\n\nfor j in range(6):\n    img, label = next(val_images)  # Doƒürulama veri k√ºmesinden g√∂r√ºnt√º ve etiket al\n\n    if isinstance(label, (list, np.ndarray)):\n        label = label[0]\n    \n    if not isinstance(label, str):\n        label = str(label)\n    \n    ax[j].imshow(img[0])  \n    ax[j].set_title(label)  \n    ax[j].axis('off')\n\nplt.tight_layout()  \nplt.suptitle('Validation Images', fontsize=24)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5 - Model Olu≈üturma","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import regularizers\n\nmodel = tf.keras.models.Sequential()\n\n# Input Layer\nmodel.add(tf.keras.layers.Flatten(input_shape=(224, 224, 3))) \n\n# Hidden Layers\nmodel.add(tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n# Output Layer\nmodel.add(tf.keras.layers.Dense(9, activation='softmax'))\n\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    restore_best_weights=True\n)\ndef lr_scheduler(epoch, lr):\n    if epoch >= 5:\n        lr *= 0.990 \n    return lr\nlr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01), \n    loss='categorical_crossentropy',\n    metrics=['accuracy'] )\n\nwith tf.device('/GPU:0'):\n    result = model.fit(\n        train_images ,\n        epochs=20,\n        batch_size=32,\n        validation_data=val_images,\n        callbacks=[early_stopping,lr_scheduler_callback])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\n\n# Loss grafiƒüi\nplt.subplot(1, 2, 1)\nplt.plot(result.history['loss'], label='Train Loss')\nplt.plot(result.history['val_loss'], label='Validation Loss')\nplt.title('Loss Grafiƒüi')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Accuracy grafiƒüi\nplt.subplot(1, 2, 2)\nplt.plot(result.history['accuracy'], label='Train Accuracy')\nplt.plot(result.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy Grafiƒüi')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6 - Model Tahmin","metadata":{}},{"cell_type":"code","source":"pred = model.predict(test_images)\npred = np.argmax(pred, axis=1)\n\nmodel.evaluate(test_images)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\npredict_data=test_data.copy()\nlabels={}\nfor l,v in test_images.class_indices.items():\n    labels.update({v:l})\npredict_data['pred']=pred\npredict_data['pred']=predict_data['pred'].apply(lambda x: labels[x])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\npredict_data=predict_data.reset_index(drop=True)\npredict_data.head(10)\npredict_data=predict_data.reset_index(drop=True)\npredict_data.head(10)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_data[predict_data['label']!=predict_data['pred']]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ### Confusion Matrix and Classification Report\ntrue_classes = test_images.classes\nclass_labels = list(test_images.class_indices.keys())  \n\n# Confusion Matrix\nconf_matrix = confusion_matrix(true_classes, pred_classes)\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\nplt.title('Confusion Matrix')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eport = classification_report(true_classes, pred_classes, target_names=class_labels)\nprint('Classification Report:')\nprint(report)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}